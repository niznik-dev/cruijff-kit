# dedupJSON.py
# This script removes duplicate entries from a JSON list of objects based on the 'input' field.
# It is intended for cleaning up datasets generated by AI assistants or other sources
# where duplicate entries may occur.

import json
import sys

if len(sys.argv) < 2:
    print("Usage: python dedupJSON.py <filename>")
    sys.exit(1)

filename = sys.argv[1]

with open(filename, 'r') as f:
    data = json.load(f)

inputs = [item['input'] for item in data]
unique_inputs = set(inputs)

if len(inputs) == len(unique_inputs):
    print(f"All inputs ({len(inputs)}) are unique.")
else:
    print(f"Found {len(inputs) - len(unique_inputs)} duplicate inputs.")
    
    # Remove duplicates while preserving order
    seen = set()
    unique_data = []
    for item in data:
        inp = item['input']
        if inp not in seen:
            seen.add(inp)
            unique_data.append(item)
    
    # Save the deduplicated data back to the file
    with open(filename, 'w') as f:
        json.dump(unique_data, f, indent=2)
    print("Duplicates removed and file updated.")